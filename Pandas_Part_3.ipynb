{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "WANZhVRu3tzI",
        "TS2YSw_EnBIc",
        "jcxyuKU72suK"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pandas Part 3\n",
        "\n",
        "**Outline:**\n",
        "- Combining and Merging Datasets\n",
        "- GroupBy Operations\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "tyzsWjO2tV7v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Packages\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "YAlyTY9novDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Combining Datasets"
      ],
      "metadata": {
        "id": "WANZhVRu3tzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandas has a function, `pd.concat()`, which has a similar syntax to `np.concatenate`"
      ],
      "metadata": {
        "id": "2LoMIxDB3u42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ser1 = pd.Series(['A', 'B', 'C'], index = [1, 2, 3])\n",
        "ser2 = pd.Series(['D', 'E', 'F'], index = [4, 5, 6])"
      ],
      "metadata": {
        "id": "oSKJjC2A3vOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser1"
      ],
      "metadata": {
        "id": "uCwfoMXs3vht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ser2"
      ],
      "metadata": {
        "id": "FFRCprC-3vx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([ser1, ser2])"
      ],
      "metadata": {
        "id": "x8nWw4tt-Xka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It also works to concatenate higher-dimensional objects, such as DataFrames:"
      ],
      "metadata": {
        "id": "MmZfMxKZ-cKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame(np.arange(6).reshape(3, 2), columns = ['A', 'B'])\n",
        "df2 = pd.DataFrame(5 + np.arange(4).reshape(2, 2), columns = ['A', 'B'])"
      ],
      "metadata": {
        "id": "vhS_wz-K-e4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "Lt7AnWq1_aIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "pT3F8VUO_brf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df1, df2])"
      ],
      "metadata": {
        "id": "BWcn0fuO_cDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "One important difference between `np.concatenate` and `pd.concat` is that Pandas\n",
        "concatenation *preserves indices*, even if the result will have duplicate indices!\n",
        "\n",
        "**Ignoring the index**. Sometimes the index itself does not matter, and you would prefer it to simply be ignored. You can specify this option using the `ignore_index` flag. With this set to `True`, the concatenation will create a new integer index for the resulting Series:"
      ],
      "metadata": {
        "id": "Nnk1qUttBCdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df1, df2], ignore_index = True)"
      ],
      "metadata": {
        "id": "6nBxHZVfBdSY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the concatenation takes place row-wise within the DataFrame (i.e.,\n",
        "`axis = 0`).\n",
        "\n",
        "Like `np.concatenate`, `pd.concat` allows specification of an axis along which concatenation will take place. Consider the following example:"
      ],
      "metadata": {
        "id": "kwweVnDOBFpm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame(np.arange(4).reshape(2, 2), columns = ['A', 'B'])\n",
        "df4 = pd.DataFrame(3 + np.arange(4).reshape(2, 2), columns = ['C', 'D'])"
      ],
      "metadata": {
        "id": "5S4YAKVZBBzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "KaDwTI4OB5mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df4"
      ],
      "metadata": {
        "id": "uTXz7ULTB7nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([df3, df4], axis = 1)"
      ],
      "metadata": {
        "id": "ov_qpkldB9zA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging Datasets"
      ],
      "metadata": {
        "id": "TS2YSw_EnBIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the following two DataFrames, which contain information on several employees in a company:"
      ],
      "metadata": {
        "id": "ak7r-oGQonZ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({'employee': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
        "                    'group': ['Accounting', 'Engineering', 'Engineering', 'HR']})\n",
        "\n",
        "df2 = pd.DataFrame({'employee': ['Lisa', 'Bob', 'Jake', 'Sue'],\n",
        "                    'hire_date': [2004, 2008, 2012, 2014]})"
      ],
      "metadata": {
        "id": "Hq2xB8tQociV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "xgVyyU-loq1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "1thgD5Fso4So"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To combine this information into a single DataFrame, we can use the `pd.merge()`\n",
        "function:"
      ],
      "metadata": {
        "id": "nEQXxzgEo5M8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.merge(df1, df2)\n",
        "df3"
      ],
      "metadata": {
        "id": "5wgCRp2upAM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   `pd.merge()` function recognizes that each DataFrame has an \"employee\" column, and automatically joins using this column as a key.\n",
        "2. Order of the \"employee\" column differs between `df1` and `df2`, and the `pd.merge()` function correctly accounts for this.\n",
        "\n"
      ],
      "metadata": {
        "id": "78eGqzGWpF9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df4 = pd.DataFrame({'group': ['Accounting', 'Engineering', 'HR'],\n",
        "                    'supervisor': ['Carly', 'Guido', 'Steve']})\n",
        "df4"
      ],
      "metadata": {
        "id": "-GwduJEGq9cq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "SlK1d7IurF7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df5 = pd.merge(df3, df4)\n",
        "df5"
      ],
      "metadata": {
        "id": "zyyemFwjrJa-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting DataFrame has an additional column with the “supervisor” information,\n",
        "where the information is repeated in one or more locations as required by the inputs."
      ],
      "metadata": {
        "id": "-Fwl7DL-sMSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specification of the Merge Key\n",
        "We’ve already seen the default behavior of `pd.merge()`: it looks for one or more matching column names between the two inputs, and uses this as the key.\n",
        "\n",
        "However, often the column names will not match so nicely, and `pd.merge()` provides a variety of options for handling this.\n",
        "\n",
        "**The on keyword**\n",
        "\n",
        "You can explicitly specify the name of the key column using the on keyword,\n",
        "which takes a column name or a list of column names:"
      ],
      "metadata": {
        "id": "yLLlX3LTtnoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1"
      ],
      "metadata": {
        "id": "FPBrCde7u5gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2"
      ],
      "metadata": {
        "id": "c1QZoPIKvRQR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df1, df2, on = 'employee')"
      ],
      "metadata": {
        "id": "Y3dVv5OIvSCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This option works only if both the left and right DataFrames have the specified column\n",
        "name."
      ],
      "metadata": {
        "id": "61n9x2U-vVgk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The left_on and right_on keywords**\n",
        "\n",
        "At times you may wish to merge two datasets with different column names; for example, we may have a dataset in which the employee name is labeled as “name” rather than “employee”.\n",
        "\n",
        "In this case, we can use the left_on and right_on keywords to specify the two column names:"
      ],
      "metadata": {
        "id": "OmD57LwKvcuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df3 = pd.DataFrame({'name': ['Bob', 'Jake', 'Lisa', 'Sue'],\n",
        "                    'salary': [70000, 80000, 120000, 90000]})\n",
        "display(df1); display(df3)"
      ],
      "metadata": {
        "id": "RyWq5hGVvrXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df1, df3, left_on = \"employee\", right_on = \"name\")"
      ],
      "metadata": {
        "id": "UQqCnA8Wv1s6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The result has a redundant column that we can drop if desired—for example, by\n",
        "using the `drop()` method of DataFrames:"
      ],
      "metadata": {
        "id": "x-jn0GK5v8Kg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df1, df3, left_on = \"employee\", right_on = \"name\").drop('name', axis = 1)"
      ],
      "metadata": {
        "id": "jN6HmAoEwGQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The left_index and right_index keywords**\n",
        "\n",
        "Sometimes, rather than merging on a column, you would instead like to merge on an index. For example, your data might look like this:"
      ],
      "metadata": {
        "id": "AorhahOkwTzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1a = df1.set_index('employee')\n",
        "df2a = df2.set_index('employee')"
      ],
      "metadata": {
        "id": "BOqVgfwbwwkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1a"
      ],
      "metadata": {
        "id": "hi0AHyKkwzRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2a"
      ],
      "metadata": {
        "id": "CtXBTI1xw2xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use the index as the key for merging by specifying the `left_index` and/or `right_index` flags in `pd.merge()`:"
      ],
      "metadata": {
        "id": "v4av7quJw4MX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df1a, df2a, left_index = True, right_index = True)"
      ],
      "metadata": {
        "id": "RtWLksjBxK22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you’d like to mix indices and columns, you can combine `left_index` with `right_on` or `left_on` with `right_index` to get the desired behavior:"
      ],
      "metadata": {
        "id": "OIBrrhDvxQa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1a"
      ],
      "metadata": {
        "id": "VInFv4kFxv6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df3"
      ],
      "metadata": {
        "id": "zSxSQUA5xx99"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df1a, df3, left_index = True, right_on = 'name')"
      ],
      "metadata": {
        "id": "sp8Z5Vu8xzQn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Specifying Set Arithmetic for Joins"
      ],
      "metadata": {
        "id": "HMvRSQKayI5J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6 = pd.DataFrame({'name': ['Peter', 'Paul', 'Mary'],\n",
        "                    'food': ['fish', 'beans', 'bread']},\n",
        "                   columns = ['name', 'food'])\n",
        "\n",
        "df7 = pd.DataFrame({'name': ['Mary', 'Joseph'],\n",
        "                    'drink': ['wine', 'beer']},\n",
        "                   columns=['name', 'drink'])"
      ],
      "metadata": {
        "id": "1PuOD71QyMls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df6"
      ],
      "metadata": {
        "id": "nV0iLxTnycb7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7"
      ],
      "metadata": {
        "id": "UIz8CNtxydgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df6, df7)"
      ],
      "metadata": {
        "id": "oiwUen0tyeoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we have merged two datasets that have only a single “name” entry in common: Mary.\n",
        "\n",
        "**Inner Join**\n",
        "\n",
        "By default, the result contains the *intersection* of the two sets of inputs; this is what is known as an *inner join*.\n",
        "\n",
        "We can specify this explicitly using the how keyword, which defaults to `inner`:"
      ],
      "metadata": {
        "id": "j-jvLue0yl8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df6, df7, how = 'inner')"
      ],
      "metadata": {
        "id": "fikwPzhYy-AL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other options for the how keyword are `outer`, `left`, and `right`.\n",
        "\n",
        "**Outer Join**\n",
        "\n",
        "An outer join returns a join over the union of the input columns, and fills in all missing values with NAs:"
      ],
      "metadata": {
        "id": "G69rOQ7K0TJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6"
      ],
      "metadata": {
        "id": "Vlx-L7cP0c-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7"
      ],
      "metadata": {
        "id": "fUL-Cchj0nAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df6, df7, how = 'outer')"
      ],
      "metadata": {
        "id": "5DKGLbhA0nTv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Left and Right Joins**\n",
        "\n",
        "The left join and right join return join over the left entries and right entries, respectively. For example:"
      ],
      "metadata": {
        "id": "akxXIo8X0noS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df6"
      ],
      "metadata": {
        "id": "eQ-Y8QSP1Abp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df7"
      ],
      "metadata": {
        "id": "M8Vq9En91C0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df6, df7, how = 'left')"
      ],
      "metadata": {
        "id": "oG26sX2F1EEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.merge(df6, df7, how = 'right')"
      ],
      "metadata": {
        "id": "NA58Q5Ud1R4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://docs.trifacta.com/download/attachments/160412683/JoinVennDiagram.png?version=1&modificationDate=1596167437085&api=v2\" width=300 height = 230 />"
      ],
      "metadata": {
        "id": "lDLVNDeizF20"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GroupBy Operations: Split, Apply, Combine"
      ],
      "metadata": {
        "id": "jcxyuKU72suK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<img src=\"https://jakevdp.github.io/figures/split-apply-combine.svg\" width=600 height = 600 />\n",
        "\n",
        "- The *split* step involves breaking up and grouping a DataFrame depending on the value of the specified key.\n",
        "- The *apply* step involves computing some function, usually an aggregate, transformation, or filtering, within the individual groups.\n",
        "- The *combine* step merges the results of these operations into an output array."
      ],
      "metadata": {
        "id": "JAackrY8HryS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
        "                   'data': range(6)}, columns=['key', 'data'])\n",
        "df"
      ],
      "metadata": {
        "id": "nz2hpqGDIYKL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can compute the most basic split-apply-combine operation with the `groupby()`\n",
        "method of DataFrames, passing the name of the desired key column:"
      ],
      "metadata": {
        "id": "RnSMgCN2JS6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('key')"
      ],
      "metadata": {
        "id": "cd5Z2HD3Jgmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that what is returned is not a set of `DataFrames`, but a `DataFrameGroupBy`\n",
        "object.\n",
        "\n",
        "To produce a result, we can apply an aggregate to this `DataFrameGroupBy` object, which will perform the appropriate apply/combine steps to produce the desired result:"
      ],
      "metadata": {
        "id": "sMRonIJ_Jjl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby('key').sum()"
      ],
      "metadata": {
        "id": "sQ8J9JNoJ9cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `sum()` method is just one possibility here; you can apply virtually any common Pandas or NumPy aggregation function, as well as virtually any valid `DataFrame` operation"
      ],
      "metadata": {
        "id": "fnCsgdC8KSiD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GroupBy on `athlete_events.csv` dataset"
      ],
      "metadata": {
        "id": "qhl_JgTbKYmS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load data from a csv file"
      ],
      "metadata": {
        "id": "NGOdCZK3LkIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = 'athlete_events.csv'\n",
        "df = pd.read_csv(filename)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "o-aYcDmwLdIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code, we will group the rows in the dataframe into the possible values in the 'Games' column, like '1896 Summer', '1900 Summer', etc.\n",
        "\n",
        "**Iteration Over Groups**\n",
        "\n",
        "The `GroupBy` object supports direct iteration over the groups, returning each group as a Series or DataFrame:"
      ],
      "metadata": {
        "id": "E9gZB2wJLzYf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "games_gb = df.groupby('Games')\n",
        "\n",
        "# Loop though the GroupBy object, printing the key and the dataframe\n",
        "for group_key, group_df in games_gb:\n",
        "    print('The group key:', group_key) # Print the key (for example, '1984 Summer')\n",
        "    print('The related df:')           # Print the values (all the rows associated with the key)\n",
        "    display(group_df)"
      ],
      "metadata": {
        "id": "bulL4-xrLoHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could just get one key by using the `.get_group(key)` method."
      ],
      "metadata": {
        "id": "fRPuVqsPNVdn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "key = '1984 Summer'\n",
        "summer84_df = games_gb.get_group(key)\n",
        "display(summer84_df.head())\n",
        "summer84_df.shape"
      ],
      "metadata": {
        "id": "wlvdeawYMHDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We could look at the 'keys' and see how many rows are associated with each."
      ],
      "metadata": {
        "id": "YfwOSB-VPKT8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "games_gb.size()"
      ],
      "metadata": {
        "id": "nIZCzjiiNbLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also go multiple levels deep. For example, group first by 'Games', then by 'Sport', then by 'Sex'"
      ],
      "metadata": {
        "id": "wfHBRD_wPTTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "complex_gb = df.groupby(['Games','Sport','Sex'])\n",
        "complex_gb.size()"
      ],
      "metadata": {
        "id": "EDrf92wfNjk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using multiple level groupby objects, if we want to get a specific dataframe, we have to call get_group by using a tuple."
      ],
      "metadata": {
        "id": "uYPn7VtXPgWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = ('2016 Summer','Weightlifting','F')         # Create a Tuple. It has to match all the group by columns.\n",
        "weightlifting_2016_df = complex_gb.get_group(t) # Call the get_group() method. This returns a DataFrame\n",
        "weightlifting_2016_df.head()"
      ],
      "metadata": {
        "id": "R22Bzi55PYUf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can get basic statistics on each groupby category using the `.agg()` method."
      ],
      "metadata": {
        "id": "B_p9nCJ1P2FX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup a new groupby object for 'NOC' and 'Sex'\n",
        "noc_gender_gb = df.groupby(['NOC','Sex'])\n",
        "\n",
        "# Call the agg() method, applying ['min','mean','max','count']. These only work on number columns\n",
        "noc_gender_df = noc_gender_gb.agg(['min','mean','max','count']) # This returns a DataFrame with 'NOC' as the index\n",
        "noc_gender_df.head()"
      ],
      "metadata": {
        "id": "CcAEp9VZPrk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From this big DataFrame, let's only look at the 'Age' column\n",
        "noc_gender_df['Age'].tail(10)"
      ],
      "metadata": {
        "id": "obsPvyK_oQ6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From this big DataFrame, let's only look at 'USA' and the 'Age' column\n",
        "# Since 'NOC' is the index, we can use the loc[] method to get just the index 'USA'\n",
        "noc_gender_df.loc['USA','Age']"
      ],
      "metadata": {
        "id": "S66qK3mcP9-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rng = np.random.RandomState(0)\n",
        "df = pd.DataFrame({'key': ['A', 'B', 'C', 'A', 'B', 'C'],\n",
        "                   'data1': range(6),\n",
        "                   'data2': rng.randint(0, 10, 6)},\n",
        "                  columns = ['key', 'data1', 'data2'])\n",
        "df"
      ],
      "metadata": {
        "id": "72Q1e0HZQR_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "my_groups = df.groupby('key')\n",
        "display(my_groups.get_group('A'))\n",
        "display(my_groups.get_group('B'))\n",
        "display(my_groups.get_group('C'))"
      ],
      "metadata": {
        "id": "1ksGwmB8qipn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another useful pattern is to pass a dictionary mapping column names to operations\n",
        "to be applied on that column:"
      ],
      "metadata": {
        "id": "joh50npbqzEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_groups_df = my_groups.agg({'data1': 'min', 'data2': 'max'})\n",
        "my_groups_df"
      ],
      "metadata": {
        "id": "M_m84eXVrLFC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}